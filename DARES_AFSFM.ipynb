{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/DARES_MedICSS2024/blob/main/DARES_AFSFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GFtACtlQRB7",
        "outputId": "9a14c956-4b5b-457b-f7bd-a12a71818569"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DARES/AF-SfMLearner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwScEIXclQmx",
        "outputId": "9b109783-7de8-448f-9aed-ab6e78a2bb01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DARES/AF-SfMLearner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkHr7_7L24RL",
        "outputId": "f550568a-d433-4d08-e15a-7c4bd09b8f88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "wQxjuLvWs8YH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dadd448-d698-4577-9161-a91df2c3eae6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets\t    export_gt_pose.py\t    LICENSE\t__pycache__\ttrain_end_to_end.py\n",
            "evaluate_depth.py   extract_left_frames.py  logs_afsfm\tREADME.md\ttrainer_end_to_end.py\n",
            "evaluate_pose.py    imgs\t\t    networks\tsplits\t\tutils.py\n",
            "export_gt_depth.py  layers.py\t\t    options.py\ttest_simple.py\tvisualize_pose.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_depth.py --data_path /content/drive/MyDrive/DARES/SCARED_Images_Resized --max_depth 150.0 --eval_mono --load_weights_folder /content/drive/MyDrive/DARES/af_sfmlearner_weights_media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6-e3sShvDSf",
        "outputId": "f0a67440-5694-484a-bfa6-f7725c147243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Loading weights from /content/drive/MyDrive/DARES/af_sfmlearner_weights_media\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "-> Computing predictions with size 320x256\n",
            "-> Evaluating\n",
            "   Mono evaluation - using median scaling\n",
            " Scaling ratios | med: 152.230 | std: 0.323\n",
            "\n",
            "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
            "&   0.060  &   0.477  &   5.100  &   0.083  &   0.966  &   0.997  &   1.000  \\\\\n",
            "\n",
            "-> Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate_pose.py --data_path /content/drive/MyDrive/DARES/SCARED_Images_Resized --load_weights_folder /content/drive/MyDrive/DARES/af_sfmlearner_weights_media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFCZ9aXEy553",
        "outputId": "0d6b3096-1439-4f0b-fe78-91031c8deaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Computing pose predictions\n",
            "\n",
            "   Trajectory error: 0.0501, std: 0.0281\n",
            "\n",
            "\n",
            "   Rotation error: 0.0034, std: 0.0022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_end_to_end.py --data_path /content/drive/MyDrive/DARES/SCARED_Images_Resized --log_dir logs_afsfm --num_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3MJI3501hdj",
        "outputId": "292c3ec4-5c56-4ea9-e154-2ffdbf80c46c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-02 16:52:26.944549: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-02 16:52:26.996154: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-02 16:52:26.996204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-02 16:52:26.997759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-02 16:52:27.005624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-02 16:52:28.143214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LoRA params initialized!\n",
            "Training model named:\n",
            "   mdp\n",
            "Models and tensorboard events files are saved to:\n",
            "   logs_afsfm\n",
            "Training is using:\n",
            "   cuda\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Using split:\n",
            "   endovis\n",
            "There are 15351 training items and 1705 validation items\n",
            "\n",
            "Training\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4343: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "head predicted_depth: torch.Size([12, 32, 256, 320])\n",
            "head predicted_depth: torch.Size([12, 32, 128, 160])\n",
            "head predicted_depth: torch.Size([12, 32, 64, 80])\n",
            "head predicted_depth: torch.Size([12, 32, 32, 40])\n",
            "torch.Size([12, 256, 320]) torch.Size([12, 128, 160]) torch.Size([12, 64, 80]) torch.Size([12, 32, 40])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/DARES/AF-SfMLearner/train_end_to_end.py\", line 12, in <module>\n",
            "    trainer.train()\n",
            "  File \"/content/drive/MyDrive/DARES/AF-SfMLearner/trainer_end_to_end.py\", line 286, in train\n",
            "    self.run_epoch()\n",
            "  File \"/content/drive/MyDrive/DARES/AF-SfMLearner/trainer_end_to_end.py\", line 309, in run_epoch\n",
            "    outputs, losses = self.process_batch(inputs)\n",
            "  File \"/content/drive/MyDrive/DARES/AF-SfMLearner/trainer_end_to_end.py\", line 458, in process_batch\n",
            "    outputs.update(self.predict_poses(inputs, features, outputs))\n",
            "UnboundLocalError: local variable 'features' referenced before assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyw4RMnY2zYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}